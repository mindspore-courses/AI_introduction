{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edcff4f2",
   "metadata": {},
   "source": [
    "# GCN科学出版物分类\n",
    "本实验基于MindSpore2.0,在启智NPU平台上运行，使用的数据集是下载的Cora和Citeseer数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef656c03",
   "metadata": {},
   "source": [
    "### 1.实验简介\n",
    "图卷积网络（Graph Convolutional Network，GCN）是近年来逐渐流行的一种神经网络结构。不同于只能用于网格结构（grid-based）数据的传统网络模型LSTM和CNN，图卷积网络能够处理具有广义拓扑图结构的数据，并深入发掘其特征和规律。\n",
    "本实验主要介绍在下载的Cora和Citeseer数据集上使用MindSpore进行图卷积网络的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643aecd6",
   "metadata": {},
   "source": [
    "### 2.实验环境\n",
    "本实验基于MindSpore2.0,在启智NPU平台上运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e836f10e",
   "metadata": {},
   "source": [
    "### 3. 图卷积神经网络概述\n",
    "GCN的本质目的就是用来提取拓扑图的空间特征。图卷积神经网络主要有两类，一类是基于空间域（spatial domain）或顶点域（vertex domain）的，另一类则是基于频域或谱域（spectral domain）的。GCN属于频域图卷积神经网络。  \n",
    "空间域方法直接将卷积操作定义在每个结点的连接关系上，它跟传统的卷积神经网络中的卷积更相似一些。在这个类别中比较有代表性的方法有Message Passing Neural Networks(MPNN), GraphSage, Diffusion Convolution Neural Networks(DCNN), PATCHY-SAN等。  \n",
    "频域方法希望借助图谱的理论来实现拓扑图上的卷积操作。从整个研究的时间进程来看：首先研究GSP（graph signal processing）的学者定义了graph上的傅里叶变化（Fourier Transformation），进而定义了graph上的卷积，最后与深度学习结合提出了Graph Convolutional Network（GCN）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb0a40",
   "metadata": {},
   "source": [
    "### 4. 图神经网络数据集\n",
    "Cora和CiteSeer是图神经网络常用的数据集，数据集官网LINQS Datasets。  \n",
    "Cora数据集包含2708个科学出版物，分为七个类别。 引用网络由5429个链接组成。 数据集中的每个出版物都用一个0/1值的词向量描述，0/1指示词向量中是否出现字典中相应的词。 该词典包含1433个独特的单词。 数据集中的README文件提供了更多详细信息。  \n",
    "CiteSeer数据集包含3312种科学出版物，分为六类。 引用网络由4732个链接组成。 数据集中的每个出版物都用一个0/1值的词向量描述，0/1指示词向量中是否出现字典中相应的词。 该词典包含3703个独特的单词。 数据集中的README文件提供了更多详细信息。  \n",
    "本实验使用Github上kimiyoung/planetoid预处理和划分好的数据集。  \n",
    "将数据集放置在data目录下，该文件夹应包含以下文件：  \n",
    "data   \n",
    "├── ind.cora.allx   \n",
    "├── ind.cora.ally   \n",
    "├── ...  \n",
    "├── ind.cora.test.index   \n",
    "├── trans.citeseer.tx  \n",
    "├── trans.citeseer.ty  \n",
    "├── ...  \n",
    "└── trans.pubmed.y  \n",
    "模型的输入包含：  \n",
    "x：已标记的训练实例的特征向量，  \n",
    "y：已标记的训练实例的one-hot标签，  \n",
    "allx：标记的和未标记的训练实例（x的超集）的特征向量，  \n",
    "graph：一个dict，格式为{index: [index_of_neighbor_nodes]}。令n为标记和未标记训练实例的数量。在graph中这n个实例的索引应从0到n-1，其顺序与allx中的顺序相同。  \n",
    "除了x，y，allx，和graph如上所述，预处理的数据集还包括：  \n",
    "1)\ttx，测试实例的特征向量，  \n",
    "2)\tty，测试实例的one-hot标签，  \n",
    "3)\ttest.index，graph中测试实例的索引，  \n",
    "4)\tally，是allx中实例的标签。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d60dd",
   "metadata": {},
   "source": [
    "### 5.实验过程\n",
    "步骤1 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa51e69-2430-4bb4-82ae-d057ed719073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ascend-professional-construction-dataset.obs.cn-north-4.myhuaweicloud.com:443/NLP/gcn.zip (12.0 MB)\n",
      "\n",
      "file_sizes: 100%|██████████████████████████| 12.5M/12.5M [00:00<00:00, 28.1MB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from download import download\n",
    "\n",
    "url = \"https://ascend-professional-construction-dataset.obs.cn-north-4.myhuaweicloud.com:443/NLP/gcn.zip\"\n",
    "\n",
    "download(url, \"./\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d078c0-6e90-4f94-8d13-927b4d394061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['DEVICE_ID']='7'\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore import Tensor\n",
    "from mindspore import context\n",
    "from mindspore.ops import operations as P\n",
    "#from mindspore.nn.layer.activation import get_activation\n",
    "from mindspore.nn import get_activation\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from gcn.src.gcn import glorot, LossAccuracyWrapper, TrainNetWrapper\n",
    "from gcn.src.dataset import get_adj_features_labels, get_mask\n",
    "from gcn.graph_to_mindrecord.writer import run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa40ab2",
   "metadata": {},
   "source": [
    "步骤2\t运行环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fd2848-0218-437f-90ce-96a294107ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.set_context(mode=context.GRAPH_MODE,device_target=\"Ascend\", save_graphs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f002d",
   "metadata": {},
   "source": [
    "步骤3 定义参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4c4611-aa0e-42cb-926b-43d875627bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'cora'\n",
    "datadir_save = './gcn/data_mr'\n",
    "datadir = os.path.join(datadir_save, dataname)\n",
    "cfg = edict({\n",
    "    'SRC_PATH': './gcn/data',\n",
    "    'MINDRECORD_PATH': datadir_save,\n",
    "    'DATASET_NAME': dataname,  # citeseer,cora\n",
    "    'mindrecord_partitions':1,\n",
    "    'mindrecord_header_size_by_bit' : 18,\n",
    "    'mindrecord_page_size_by_bit' : 20,\n",
    "\n",
    "    'data_dir': datadir,\n",
    "    'seed' : 123,\n",
    "    'train_nodes_num':140,\n",
    "    'eval_nodes_num':500,\n",
    "    'test_nodes_num':1000\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904dd4d",
   "metadata": {},
   "source": [
    "步骤4\t转换数据格式为mindrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1f8fd6-6e4e-449e-91a4-a03eb6abbb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Graph To Mindrecord ==============\n",
      "Init writer  ...\n",
      "exec task 0, parallel: False ...\n",
      "Node task is 0\n",
      "transformed 512 record...\n",
      "transformed 1024 record...\n",
      "transformed 1536 record...\n",
      "transformed 2048 record...\n",
      "transformed 2560 record...\n",
      "Processed 2708 lines for nodes.\n",
      "transformed 2708 record...\n",
      "exec task 0, parallel: False ...\n",
      "Edge task is 0\n",
      "transformed 512 record...\n",
      "transformed 1024 record...\n",
      "transformed 1536 record...\n",
      "transformed 2048 record...\n",
      "transformed 2560 record...\n",
      "transformed 3072 record...\n",
      "transformed 3584 record...\n",
      "transformed 4096 record...\n",
      "transformed 4608 record...\n",
      "transformed 5120 record...\n",
      "transformed 5632 record...\n",
      "transformed 6144 record...\n",
      "transformed 6656 record...\n",
      "transformed 7168 record...\n",
      "transformed 7680 record...\n",
      "transformed 8192 record...\n",
      "transformed 8704 record...\n",
      "transformed 9216 record...\n",
      "transformed 9728 record...\n",
      "transformed 10240 record...\n",
      "transformed 10752 record...\n",
      "Processed 10858 lines for edges.\n",
      "transformed 10858 record...\n",
      "--------------------------------------------\n",
      "END. Total time: 8.289729356765747\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 转换数据格式\n",
    "print(\"============== Graph To Mindrecord ==============\")\n",
    "run(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e06bf9",
   "metadata": {},
   "source": [
    "步骤5 定义GCN网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fd9440-f665-4f05-bd42-8dc00f89b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigGCN():\n",
    "    learning_rate = 0.01\n",
    "    epochs = 200\n",
    "    hidden1 = 16\n",
    "    dropout = 0.5\n",
    "    weight_decay = 5e-4\n",
    "    early_stopping = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505fd5b",
   "metadata": {},
   "source": [
    "步骤6 定义GCN网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a306a345-fdc1-4513-81b0-8bfc45ec4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Cell):\n",
    "    \"\"\"\n",
    "    GCN graph convolution layer.\n",
    "\n",
    "    Args:\n",
    "        feature_in_dim (int): The input feature dimension.\n",
    "        feature_out_dim (int): The output feature dimension.\n",
    "        dropout_ratio (float): Dropout ratio for the dropout layer. Default: None.\n",
    "        activation (str): Activation function applied to the output of the layer, eg. 'relu'. Default: None.\n",
    "\n",
    "    Inputs:\n",
    "        - **adj** (Tensor) - Tensor of shape :math:`(N, N)`.\n",
    "        - **input_feature** (Tensor) - Tensor of shape :math:`(N, C)`.\n",
    "\n",
    "    Outputs:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 feature_in_dim,\n",
    "                 feature_out_dim,\n",
    "                 dropout_ratio=None,\n",
    "                 activation=None):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_dim = feature_in_dim\n",
    "        self.out_dim = feature_out_dim\n",
    "        self.weight_init = glorot([self.out_dim, self.in_dim])\n",
    "        self.fc = nn.Dense(self.in_dim,\n",
    "                           self.out_dim,\n",
    "                           weight_init=self.weight_init,\n",
    "                           has_bias=False)\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        if self.dropout_ratio is not None:\n",
    "            self.dropout = nn.Dropout(keep_prob=1-self.dropout_ratio)\n",
    "        self.dropout_flag = self.dropout_ratio is not None\n",
    "        self.activation = get_activation(activation)\n",
    "        self.activation_flag = self.activation is not None\n",
    "        self.matmul = P.MatMul()\n",
    "\n",
    "    def construct(self, adj, input_feature):\n",
    "        dropout = input_feature\n",
    "        if self.dropout_flag:\n",
    "            dropout = self.dropout(dropout)\n",
    "\n",
    "        fc = self.fc(dropout)\n",
    "        output_feature = self.matmul(adj, fc)\n",
    "\n",
    "        if self.activation_flag:\n",
    "            output_feature = self.activation(output_feature)\n",
    "        return output_feature\n",
    "\n",
    "\n",
    "class GCN(nn.Cell):\n",
    "    \"\"\"\n",
    "    GCN architecture.\n",
    "\n",
    "    Args:\n",
    "        config (ConfigGCN): Configuration for GCN.\n",
    "        adj (numpy.ndarray): Numbers of block in different layers.\n",
    "        feature (numpy.ndarray): Input channel in each layer.\n",
    "        output_dim (int): The number of output channels, equal to classes num.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, adj, feature, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.adj = Tensor(adj)\n",
    "        self.feature = Tensor(feature)\n",
    "        input_dim = feature.shape[1]\n",
    "        self.layer0 = GraphConvolution(input_dim, config.hidden1, activation=\"relu\", dropout_ratio=config.dropout)\n",
    "        self.layer1 = GraphConvolution(config.hidden1, output_dim, dropout_ratio=None)\n",
    "\n",
    "    def construct(self):\n",
    "        output0 = self.layer0(self.adj, self.feature)\n",
    "        output1 = self.layer1(self.adj, output0)\n",
    "        return output1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99745d7c",
   "metadata": {},
   "source": [
    "步骤7 定义训练、评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62a16097-bcf3-4b2c-9e37-93b9bae1e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(args_opt):\n",
    "    \"\"\"Train model.\"\"\"\n",
    "    np.random.seed(args_opt.seed)\n",
    "    config = ConfigGCN()\n",
    "    adj, feature, label = get_adj_features_labels(args_opt.data_dir)\n",
    "\n",
    "    nodes_num = label.shape[0]\n",
    "    train_mask = get_mask(nodes_num, 0, args_opt.train_nodes_num)\n",
    "    eval_mask = get_mask(nodes_num, args_opt.train_nodes_num, args_opt.train_nodes_num + args_opt.eval_nodes_num)\n",
    "    test_mask = get_mask(nodes_num, nodes_num - args_opt.test_nodes_num, nodes_num)\n",
    "\n",
    "    class_num = label.shape[1]\n",
    "    gcn_net = GCN(config, adj, feature, class_num)\n",
    "    gcn_net.add_flags_recursive(fp16=True)\n",
    "\n",
    "    eval_net = LossAccuracyWrapper(gcn_net, label, eval_mask, config.weight_decay)\n",
    "    test_net = LossAccuracyWrapper(gcn_net, label, test_mask, config.weight_decay)\n",
    "    train_net = TrainNetWrapper(gcn_net, label, train_mask, config)\n",
    "\n",
    "    loss_list = []\n",
    "    for epoch in range(config.epochs):\n",
    "        t = time.time()\n",
    "\n",
    "        train_net.set_train()\n",
    "        train_result = train_net()\n",
    "        train_loss = train_result[0].asnumpy()\n",
    "        train_accuracy = train_result[1].asnumpy()\n",
    "\n",
    "        eval_net.set_train(False)\n",
    "        eval_result = eval_net()\n",
    "        eval_loss = eval_result[0].asnumpy()\n",
    "        eval_accuracy = eval_result[1].asnumpy()\n",
    "\n",
    "        loss_list.append(eval_loss)\n",
    "        if epoch%10==0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch), \"train_loss=\", \"{:.5f}\".format(train_loss),\n",
    "                \"train_acc=\", \"{:.5f}\".format(train_accuracy), \"val_loss=\", \"{:.5f}\".format(eval_loss),\n",
    "                \"val_acc=\", \"{:.5f}\".format(eval_accuracy), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "        if epoch > config.early_stopping and loss_list[-1] > np.mean(loss_list[-(config.early_stopping+1):-1]):\n",
    "            print(\"Early stopping...\")\n",
    "            break\n",
    "\n",
    "    t_test = time.time()\n",
    "    test_net.set_train(False)\n",
    "    test_result = test_net()\n",
    "    test_loss = test_result[0].asnumpy()\n",
    "    test_accuracy = test_result[1].asnumpy()\n",
    "    print(\"Test set results:\", \"loss=\", \"{:.5f}\".format(test_loss),\n",
    "          \"accuracy=\", \"{:.5f}\".format(test_accuracy), \"time=\", \"{:.5f}\".format(time.time() - t_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318943d",
   "metadata": {},
   "source": [
    "步骤8 启动训练、评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4e659a-c43c-4f94-b2f4-e6274520f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "Epoch: 0000 train_loss= 1.95375 train_acc= 0.62857 val_loss= 1.94876 val_acc= 0.35800 time= 22.02676\n",
      "Epoch: 0010 train_loss= 1.86080 train_acc= 0.82857 val_loss= 1.90495 val_acc= 0.50000 time= 0.00418\n",
      "Epoch: 0020 train_loss= 1.75320 train_acc= 0.85000 val_loss= 1.86154 val_acc= 0.52400 time= 0.00409\n",
      "Epoch: 0030 train_loss= 1.60470 train_acc= 0.87857 val_loss= 1.80616 val_acc= 0.55800 time= 0.00405\n",
      "Epoch: 0040 train_loss= 1.46578 train_acc= 0.92857 val_loss= 1.74064 val_acc= 0.59000 time= 0.00400\n",
      "Epoch: 0050 train_loss= 1.30271 train_acc= 0.95000 val_loss= 1.66939 val_acc= 0.66400 time= 0.00413\n",
      "Epoch: 0060 train_loss= 1.18308 train_acc= 0.95714 val_loss= 1.59799 val_acc= 0.72000 time= 0.00401\n",
      "Epoch: 0070 train_loss= 1.06383 train_acc= 0.97857 val_loss= 1.52205 val_acc= 0.76200 time= 0.00465\n",
      "Epoch: 0080 train_loss= 0.95960 train_acc= 0.97143 val_loss= 1.45305 val_acc= 0.77200 time= 0.00416\n",
      "Epoch: 0090 train_loss= 0.86225 train_acc= 0.97143 val_loss= 1.39328 val_acc= 0.77400 time= 0.00412\n",
      "Epoch: 0100 train_loss= 0.80617 train_acc= 0.97143 val_loss= 1.34127 val_acc= 0.78000 time= 0.00410\n",
      "Epoch: 0110 train_loss= 0.76188 train_acc= 0.97857 val_loss= 1.28847 val_acc= 0.78000 time= 0.00406\n",
      "Epoch: 0120 train_loss= 0.71766 train_acc= 0.97143 val_loss= 1.25170 val_acc= 0.79000 time= 0.00412\n",
      "Epoch: 0130 train_loss= 0.68409 train_acc= 0.98571 val_loss= 1.21680 val_acc= 0.78400 time= 0.00406\n",
      "Epoch: 0140 train_loss= 0.62480 train_acc= 0.99286 val_loss= 1.18628 val_acc= 0.78600 time= 0.00417\n",
      "Epoch: 0150 train_loss= 0.60009 train_acc= 0.98571 val_loss= 1.15766 val_acc= 0.78600 time= 0.00420\n",
      "Epoch: 0160 train_loss= 0.58994 train_acc= 0.98571 val_loss= 1.13201 val_acc= 0.78600 time= 0.00414\n",
      "Epoch: 0170 train_loss= 0.58475 train_acc= 0.98571 val_loss= 1.11237 val_acc= 0.78600 time= 0.00415\n",
      "Epoch: 0180 train_loss= 0.55069 train_acc= 0.99286 val_loss= 1.09433 val_acc= 0.78800 time= 0.00412\n",
      "Epoch: 0190 train_loss= 0.52701 train_acc= 1.00000 val_loss= 1.07699 val_acc= 0.78000 time= 0.00450\n",
      "Test set results: loss= 1.01792 accuracy= 0.81700 time= 1.04644\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "print(\"============== Starting Training ==============\")\n",
    "train_eval(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d2d75-9260-447c-9a5a-749539e2739a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce97f6-200d-4fa7-ac3e-5b87820321e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d058cbe-8bac-44d2-9041-767839b025bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
